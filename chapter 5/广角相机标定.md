本章将介绍contrib扩展模块中相机标定模块，将以示例的形式重点介绍全景相机和多相机的联合标定。其中对广角相机标定包括广角相机的标定、校正和立体重建等三部分；对多相机标定包括“随机”图案的介绍和多相机标定两部分。


## 5.1.1	目标
在本节教程中，我们将介绍如何对广角相机进行标定，主要内容包括：

1.	标定单台相机
2.	标定一对立体相机
3.	校正图像、大幅消除失真
4.	从两幅具有大视场的立体图像中进行三维重建
5.	与opencv/calib3d/中的鱼眼模型进行比较

## 5.1.2	 单个相机标定
标定相机的第一步是获取标定图案并拍摄一些照片。OpenCV支持多种图案，比如棋盘格和圆形网格。还可以使用一个名为random pattern的新图案，我们称为“随机图案”。关于随机图案的更多细节，读者自行查阅官方文档opencv_contrib/modules/ccalib进行了解。

第二步是从标定图案中提取角点。针对棋盘格，可以使用OpenCV基础库中的函数cv::findChessboardCorners提取角点；针对圆形网格，可以使用函数cv::findCirclesGrid提取角点；针对随机图案，可以使用opencv_contrib/modules/ccalib/src/randomPattern.hpp中的randomPatternCornerFinder类提取角点。之后将图像中的角点坐标保存在imagePoints这样类型的变量中。imagePoints的类型可以是std::vector<std::vector<cv::Vec2f>>，第一个vector容器存储每一张图片的角点，第二个vector容器存储同一图案的所有图片中的角点。imagePoints的类型也可以是std::vector<cv::Mat>，其中cv::Mat的类型为CV_32FC2。

此外，还需要世界坐标中相应的三维点坐标。我们可以任意设定世界坐标系，并通过图案的物理大小计算三维点的坐标。之后将这些点保存在objectPoints类型中，类似于imagePoints，objectPoints类型可以是std::vector<std::vector<Vec3f>>或std::vector<cv::Mat>类型，其中cv::Mat为CV_32FC3类型。

最后一个需要输入的参数是图像的尺寸大小。

**警告
*objectPoints和imagePoints的大小必须相同，因为它们彼此对应。***

在官方示例中，标定所需要的数据被存放在一个xml文件中，我们可以通过opencv_contrib/modules/ccalib/tutorial/data/omni_calib_data.xml找到它。文件中存储了一个objectPoints、imagePoints和imageSize这三个类数据。代码清单5-1是加载该文件的代码

```cpp
代码清单5-1：加载数据
cv::FileStorage fs("omni_calib_data.xml", cv::FileStorage::READ);
std::vector<cv::Mat> objectPoints, imagePoints;
cv::Size imgSize;
fs["objectPoints"] >> objectPoints;
fs["imagePoints"] >> imagePoints;
fs["imageSize"] >> imgSize;
```

**提示
*如果没有下载opencv_contrib安装包，可以在“小白学视觉”公众号后台回复“omni_calib_data”获取这个数据文件***

然后定义一些变量来存储输出参数，并运行标定代码，具体代码如下：

```cpp
代码清单5-2：标定代码
cv::Mat K, xi, D, idx;
int flags = 0;
cv::TermCriteria critia(cv::TermCriteria::COUNT + cv::TermCriteria::EPS, 200, 0.0001);
std::vector<cv::Mat> rvecs, tvecs;
double rms = cv::omnidir::calibrate(objectPoints, imagePoints, imgSize, K, xi, D, rvecs, tvecs, flags, critia, idx);
```

K, xi, D是内部参数，rvecs和tvecs是存储图案姿态的外部参数。它们的深度都是CV_64F。xi是广角相机模型的一个单值变量。idx是一个CV_32S的Mat，存储实际用于校准的图像索引，这是因为一些图像在初始化步骤中失败，所以在最后的优化中没有使用它们。返回值rms是重投影误差的均方根值。

校准支持一些功能，flags是一些特性的枚举变量，包括：

-	cv::omnidir::CALIB_FIX_SKEW
-	cv::omnidir::CALIB_FIX_K1
-	cv::omnidir::CALIB_FIX_K2
-	cv::omnidir::CALIB_FIX_P1
-	cv::omnidir::CALIB_FIX_P2
-	cv::omnidir::CALIB_FIX_XI
-	cv::omnidir::CALIB_FIX_GAMMA
-	cv::omnidir::CALIB_FIX_CENTER

我们可以指定flags来在标定期间修正参数。使用“+”操作符可以设置多个参数。例如，CALIB_FIX_SKEW+CALIB_FIX_K1意味着修正kew和K1。

criteria是优化过程中的停止条件，例如，cv::TermCriteria(cv::TermCriteria::COUNT + cv::TermCriteria::EPS, 200, 0.0001)，即迭代200次，或者当相对变化小于0.0001时停止。

## 5.1.3	立体标定
立体标定是同时标定两个摄像机。输出参数包括两台相机的相机内部参数和相机的相对位姿。为了确定相对位姿，两个相机必须同时拍摄相同的图案，这样两个相机的objectPoints是相同的。

首先根据前一小节的方法分别检测两个相机拍摄图像的角点，以获得imagePoints1和imagePoints2。然后计算共同的objectPoints。

立体标定所需要的数据被存放在一个xml文件中，我们可以通过opencv_contrib/modules/ccalib/tutorial/data/omni_stereocalib_data.xml找到它。可以通过代码清单5-3中的代码加载数据。

**提示
*同样可以在“小白学视觉”公众号后台回复“omni_stereocalib_data.xml”获取这个数据文件***

```cpp
代码清单5-3：加载立体标定数据
cv::FileStorage fs("omni_stereocalib_data.xml", cv::FileStorage::READ);
std::vector<cv::Mat> objectPoints, imagePoints1, imagePoints2;
cv::Size imgSize1, imgSize2;
fs["objectPoints"] >> objectPoints;
fs["imagePoints1"] >> imagePoints1;
fs["imagePoints2"] >> imagePoints2;
fs["imageSize1"] >> imgSize1;
fs["imageSize2"] >> imgSize2;
```
之后利用代码清单5-4中的代码进行立体标定。

```cpp
代码清单5-4：立体标定
cv::Mat K1, K2, xi1, xi2, D1, D2;
int flags = 0;
cv::TermCriteria critia(cv::TermCriteria::COUNT + cv::TermCriteria::EPS, 200, 0.0001);
std::vector<cv::Mat> rvecsL, tvecsL;
cv::Mat rvec, tvec;
double rms = cv::omnidir::stereoCalibrate(objectPoints, imagePoints1, imagePoints2, imgSize1, imgSize2, K1, xi1, D1, K2, xi2, D2, rvec, tvec, rvecsL, tvecsL, flags, critia, idx);
```

程序中的rvec和tvec是第一个和第二个照相机之间的转换。rvecsL和tvecsL是空间中标定物体和第一个摄像头之间的转换。

## 5.1.4	图像矫正
全景图像的失真很大，与人眼观测的结果有很大差异。但是如果摄像机的参数已知，可以对全景图像进行矫正。图5-1是一个360度水平视场全景图像的例子。

<p align="center">
<img src="https://img-blog.csdnimg.cn/20200224124608869.png" height="300">
</p>
 

矫正后，会生成一张类似透视图的图像。接下来将利用ccalib模块中的cv::omnidir::undistortImage函数对全景图像进行矫正。

```cpp
代码清单5-5：全景图像校正函数
cv::omnidir::undistortImage(distorted, undistorted, K, D, xi, int flags, Knew, new_size)
```

函数中参数distorted和undistorted分别为原始图像和矫正后的图象。K、D、xi为相机参数。Knew和new_size是矫正后图像的相机矩阵和图像大小。flags是矫正类型，它可以选择的类型如下：

-	RECTIFY_PERSPECTIVE: 对透视图进行透视矫正，会丢失部分视场。
-	RECTIFY_CYLINDRICAL: 矫正成圆柱形图像，保留所有视场。
-	RECTIFY_STEREOGRAPHIC: 矫正成可能会失去一点视场的立体图像。
-	RECTIFY_LONGLATI: 矫正成像世界地图的经纬度图。这种矫正可以用于立体重建，但可能不方便查看。

图5-2、图5-3、图5-4和图5-5分别是这四种矫正后的结果

<p align="center">
<img src="https://img-blog.csdnimg.cn/20200224125217615.png" height="300">
</p>

<p align="center">
<img src="https://img-blog.csdnimg.cn/20200224125252628.png" height="300">
</p>

<p align="center">
<img src="https://img-blog.csdnimg.cn/2020022412531392.png" height="300">
</p>

<p align="center">
<img src="https://img-blog.csdnimg.cn/2020022412542145.png" height="300">
</p>
 
可以看出，透视矫正后的图像只保留了很少的视野。柱面矫正保留了所有的视野，只在画面底部中间位置不自然。在底部中间的位置，立体校正畸变小于柱面矫正，但其他位置的畸变较大，并且无法保留所有视场。对于失真非常大的图像，经纬度矫正效果不好，但是可以在一条线上形成对极约束，因此可以将立体匹配应用于全景图像。

**注意
*为了获得更好的效果，应该谨慎选择参数Knew，它与相机有关。通常来说，较小的焦距会导致较小的视野，反之亦然。下面是一些推荐的设置。***

针对 RECTIFY_PERSPECTIVE （透视矫正）方法，Knew计算方法如代码清单5-6中所示。

```cpp
代码清单5-6：计算Knew
Knew = Matx33f(new_size.width/4, 0, new_size.width/2, 0, new_size.height/4, new_size.height/2, 0, 0, 1);
```
针对 RECTIFY_CYLINDRICAL, RECTIFY_STEREOGRAPHIC, RECTIFY_LONGLATI（柱面校正、立体校正、经纬度校正）方法，Knew计算方法如代码清单5-7中所示。

```cpp
代码清单5-7：计算Knew
Knew = Matx33f(new_size.width/3.1415, 0, 0, 0, new_size.height/3.1415, 0,0, 0, 1);
```

此外，可能需要更改(u0, v0)以获得更好的视图。

## 5.1.5	立体重建
立体重建是从标定好的立体像机对中重建空间中的三维点。这是计算机视觉中的一个基本问题。但是，对于全景摄像机来说，由于畸变较大使得重建困难。常规方法是将图像校正为透视图像，并在透视图像中进行立体重建。但是，上一小节表明，对图像进行透视矫正会损失太多的视场，这就浪费了全景摄像机最大的优势——大视场。

立体重建的第一步是对图像进行立体矫正，使极线成为水平线。我们使用经纬度矫正来保留所有视场。也可以使用透视矫正，但并不推荐这样做。第二步是通过立体匹配来获得视差图。最后，通过视差图生成空间中的三维点。

广角相机立体重建的函数是omnidir::stereoReconstruct。接下来我们将用一个例子来说明如何使用它进行立体重建。

首先，按照前面描述的步骤标定一对立体像机，并获取K1，D1，xi1，K2，D2，xi2，rvec，tvec等参数。然后分别从第一台和第二台相机读取两个图像，例如image1和image2，如图5-6中所示。

<p align="center">
<img src="https://img-blog.csdnimg.cn/20200224125836319.png">
</p>

然后，运行omnidir :: stereoReconstruct，示例代码在代码清单5-8中给出。

```cpp
代码清单5-8：三维重建
cv::Size imgSize = img1.size();
int numDisparities = 16*5;
int SADWindowSize = 5;
cv::Mat disMap;
int flag = cv::omnidir::RECTIFY_LONGLATI;
int pointType = omnidir::XYZRGB;
// the range of theta is (0, pi) and the range of phi is (0, pi)
cv::Matx33d KNew(imgSize.width / 3.1415, 0, 0, 0, imgSize.height / 3.1415, 0, 0, 0, 1);
Mat imageRec1, imageRec2, pointCloud;
cv::omnidir::stereoReconstruct(img1, img2, K1, D1, xi1, K2, D2, xi2, R, T, flag, numDisparities, SADWindowSize, disMap, imageRec1, imageRec2, imgSize, KNew, pointCloud);
```

其中，变量flag表示校正类型，只能使用RECTIFY_LONGLATI(推荐)或者RECTIFY_PERSPECTIVE。numDisparities是最大视差值，SADWindowSize是cv :: StereoSGBM的窗口大小。pointType是一个用来定义点云类型的标志，omnidir :: XYZRGB类型表示每个点都是6维向量，前三个元素是xyz坐标，后三个元素是rgb颜色信息。另一种类型omnidir::XYZ表示每个点都是三维的，并且只有XYZ坐标。imageRec1和imagerec2分别是第一幅和第二幅图像校正后的图像。它们的极线具有相同的y坐标，这个特点使得立体匹配变得更容易，结果如图5-7所示。
 
<p align="center">
<img src="https://img-blog.csdnimg.cn/20200224130019967.png" height="300">
</p>

从结果中可以看出它们对齐的很好。变量disMap存储了通过函数cv :: StereoSGBM从imageRec1和imageRec2计算出的视差图。图5-7中两张图片的视差图如图5-8所示。

<p align="center">
<img src="https://img-blog.csdnimg.cn/20200224130123151.png" height="300">
</p>
 
有了视差图后，我们可以计算每个像素对应的3D位置。点云存储在变量pointCloud中，pointCloud是3通道或6通道cv :: Mat。计算的点云结果如图5-9所示。

<p align="center">
<img src="https://img-blog.csdnimg.cn/20200224130231143.png" height="300">
</p>


